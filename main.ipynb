{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70306 images belonging to 38 classes.\n",
      "Found 17561 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=40,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_path = 'dataset/'\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(train_path, \n",
    "                                               target_size=IMG_SIZE,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               subset = 'training') \n",
    "\n",
    "test_dataset = train_datagen.flow_from_directory(train_path, \n",
    "                                           target_size=IMG_SIZE,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False,\n",
    "                                           subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m2198/2198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 148ms/step - accuracy: 0.6865 - loss: 1.0622\n",
      "Epoch 2/3\n",
      "\u001b[1m2198/2198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 146ms/step - accuracy: 0.8125 - loss: 0.5857\n",
      "Epoch 3/3\n",
      "\u001b[1m2198/2198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 149ms/step - accuracy: 0.8369 - loss: 0.5141\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_dataset.num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.8848 - loss: 0.3610\n",
      "Test accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 142ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "predictions = model.predict(test_dataset)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8743237856614088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true_labels = test_dataset.classes\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       504\n",
      "           1       0.92      0.81      0.86       496\n",
      "           2       0.92      0.95      0.94       440\n",
      "           3       0.86      0.89      0.88       502\n",
      "           4       0.88      0.84      0.86       454\n",
      "           5       0.96      0.94      0.95       420\n",
      "           6       0.96      0.84      0.90       456\n",
      "           7       0.86      0.83      0.85       410\n",
      "           8       0.99      0.97      0.98       476\n",
      "           9       0.86      0.92      0.89       477\n",
      "          10       0.99      0.98      0.99       464\n",
      "          11       0.82      0.90      0.86       472\n",
      "          12       0.93      0.84      0.88       480\n",
      "          13       0.99      0.94      0.96       430\n",
      "          14       0.92      0.95      0.94       423\n",
      "          15       0.97      0.98      0.98       502\n",
      "          16       0.93      0.88      0.90       459\n",
      "          17       0.85      0.95      0.90       432\n",
      "          18       0.87      0.86      0.86       478\n",
      "          19       0.83      0.80      0.81       497\n",
      "          20       0.93      0.91      0.92       484\n",
      "          21       0.87      0.84      0.86       484\n",
      "          22       0.81      0.88      0.84       456\n",
      "          23       0.89      0.93      0.91       445\n",
      "          24       0.87      0.91      0.89       505\n",
      "          25       0.96      0.99      0.98       434\n",
      "          26       0.98      0.97      0.98       443\n",
      "          27       0.93      0.90      0.91       456\n",
      "          28       0.81      0.89      0.85       425\n",
      "          29       0.73      0.69      0.71       480\n",
      "          30       0.84      0.80      0.82       462\n",
      "          31       0.76      0.87      0.81       470\n",
      "          32       0.78      0.58      0.67       436\n",
      "          33       0.75      0.75      0.75       435\n",
      "          34       0.62      0.71      0.66       456\n",
      "          35       0.93      0.91      0.92       490\n",
      "          36       0.81      0.94      0.87       447\n",
      "          37       0.92      0.83      0.87       481\n",
      "\n",
      "    accuracy                           0.87     17561\n",
      "   macro avg       0.88      0.87      0.87     17561\n",
      "weighted avg       0.88      0.87      0.87     17561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_classes)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
